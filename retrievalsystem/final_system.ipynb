{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier l√§uft dann unser fertiges Retrieval System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector-Space-Model-Retrieval mit Dirichlet-Smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tira ir-datasets python-terrier\n",
    "\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pt_dataset\n",
    "from textanalysis.preprocessing import PreprocessorSpacy as Preprocessor\n",
    "from indexing.indexing import Index\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "corpus_preprocessed = list(zip(\n",
    "    [doc[0] for doc in corpus],\n",
    "    map(preprocessor.preprocess, [doc[1] for doc in corpus])\n",
    "))\n",
    "\n",
    "index = Index(corpus_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_probability(index, term, doc_id):\n",
    "    \"\"\"\n",
    "    Calculates the conditional probability of a term give a document.\n",
    "    :param index: index to get frequency data from\n",
    "    :param term: term to calculate the probability for\n",
    "    :param doc_id: document to calculate the probability for\n",
    "    \"\"\"\n",
    "    frequency = index.get_term_frequency(term, doc_id)\n",
    "    doc_sum = 0\n",
    "    for t in index.get_index_terms():\n",
    "        doc_sum += index.get_term_frequency(t, doc_id)\n",
    "    if doc_sum == 0:\n",
    "        return 0\n",
    "    else:   \n",
    "        return frequency/doc_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collection_probability(index, term):\n",
    "    \"\"\"\n",
    "    Calculates the conditional probability of a term give a document collection.\n",
    "    :param index: index to get frequency data from\n",
    "    :param term: term to calculate the probability for\n",
    "    \"\"\"\n",
    "    frequencies = []\n",
    "    doc_sums = []\n",
    "    \n",
    "    for doc_id in index.get_document_ids():\n",
    "        frequencies.append(index.get_term_frequency(term, doc_id))\n",
    "        doc_sum = 0\n",
    "        for t in index.get_index_terms():\n",
    "            doc_sum += index.get_term_frequency(t, doc_id)\n",
    "        doc_sums.append(doc_sum)\n",
    "        \n",
    "    return sum(frequencies)/sum(doc_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(index, doc_id, alpha):\n",
    "    \"\"\"\n",
    "    Calculates the dirichlet smoothing weighting factor for a given document and alpha value\n",
    "    :param index: index to get frequency data from\n",
    "    :param doc_id: document to calculate the weight factor for\n",
    "    :param alpha: alpha-prior for the dirichlet smoothing\n",
    "    \"\"\"\n",
    "    doc_len = 0\n",
    "    for term in index.get_index_terms():\n",
    "        doc_len += index.get_term_frequency(term, doc_id)\n",
    "    return alpha / (doc_len + alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirichlet_term_probability(index, term, doc_id, alpha):\n",
    "    \"\"\"\n",
    "    Calculates the conditional probability of a term give a document using Dirichlet smoothing.\n",
    "    :param index: index to get frequency data from\n",
    "    :param term: term to calculate the probability for\n",
    "    :param doc_id: document to calculate the probability for\n",
    "    :param alpha: alpha-prior for the dirichlet interpolation\n",
    "    \"\"\"\n",
    "    omega = weight(index, doc_id, alpha)\n",
    "    p1 = document_probability(index, term, doc_id)\n",
    "    p2 = collection_probability(index, term)\n",
    "    return (1-omega) * p1 + omega * p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def dirichlet_score(index, query, doc_id, alpha):\n",
    "    \"\"\"\n",
    "    Calculates the relevance of a document given a query using Dirichlet smoothing.\n",
    "    :param index: index to get relevance data from\n",
    "    :param query: query to calculate the relevance for\n",
    "    :param doc_id: document to calculate the relevance for\n",
    "    :param alpha: alpha paramter for Dirichlet smoothing\n",
    "    \"\"\"\n",
    "    rho = 1\n",
    "    for term in query:\n",
    "        rho += log(dirichlet_term_probability(index, term, doc_id, alpha))\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hier Output anpassen: noch query und docid anzeigen?\"\n",
    "def dirichlet_query(index, preprocessor, text, alpha=1000, topK=-1):\n",
    "    \"\"\"\n",
    "    Queries a given text against the given index using a Dirichlet smoothed language model\n",
    "    :param preprocessor: preprocessor instance to process the query with\n",
    "    :param index: the index data to query against\n",
    "    :param text: query text\n",
    "    :param alpha: alpha-parameter for Dirichlet smoothing\n",
    "    :param topK: number of top results to return\n",
    "    :return: list of (doc_id, score) tuples descending by score for all documents in the vector space\n",
    "    \"\"\"\n",
    "    query = preprocessor.preprocess(text)\n",
    "    scores = {}\n",
    "    for doc_id in index.get_document_ids():\n",
    "        scores[doc_id] = dirichlet_score(index, query, doc_id, alpha=alpha)\n",
    "        \n",
    "    return sorted(scores.items(), key=lambda item: item[1], reverse=True)[:topK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = dirichlet_query(index, preprocessor, \"information retrieval\", topK=10)\n",
    "persist_and_normalize_run(run, system_name='retrieval_system', default_output='../runs')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
